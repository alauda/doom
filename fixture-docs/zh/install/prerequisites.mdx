---
weight: 30
i18n:
  title:
    en: Prerequisites
---

# 先决条件

**注意：** 平台目前**不支持在已有 Kubernetes 环境中直接安装管理集群**。请提前准备符合要求的虚拟机或物理机，并严格按照以下先决条件完成部署前准备。

以下内容详细说明了安装管理集群所需的硬件、网络、操作系统与内核要求，以及节点预处理步骤。

### 1. 机器资源要求

**提示：** 本节描述构建高可用管理集群的最低硬件要求。若您已完成容量规划，请参照 [容量规划](#scale) 准备相应资源，或在安装后根据需要进行扩容。

#### 1.1 基本配置要求

至少需提供 **3 台** 物理机或虚拟机作为管理集群的控制节点，各节点最低配置如下：

| **类别** | **最低要求**                                                 |
| -------- | ------------------------------------------------------------ |
| **CPU**  | ≥ 8 核，主频 ≥ 2.5GHz<br />不得超售；关闭节能模式            |
| **内存** | ≥ 16GB<br />不得超售；建议采用至少六通道 DDR4                |
| **硬盘** | 单块设备 IOPS ≥ 2000<br />吞吐量 ≥ 200MB/s<br />必须采用 SSD |

#### 1.2 ARM 架构要求

对于 ARM 架构（如鲲鹏 920），建议配置相对于 x86 最低配置提高至 **2 倍**，但不得低于 **1.5 倍**。
例如：若 x86 要求为 8 核 16GB，则 ARM 最低应达到 12 核 24GB，推荐配置为 16 核 32GB。

#### 1.3 特殊环境说明

- **单节点部署**：若仅提供 1 台机器，可安装单节点管理集群，但**仅限非生产环境使用**。生产环境必须至少配置 3 台机器以实现高可用。

---

### 2. 支持的操作系统与内核

#### 2.1 x86 架构

**Red Hat Enterprise Linux (RHEL)**

- **支持版本及内核：**
  - RHEL 7.8：`3.10.0-1127.el7.x86_64`
  - RHEL 8.0 至 8.6：`4.18.0-80.el8.x86_64` 至 `4.18.0-372.9.1.el8.x86_64`
- **注意：** RHEL 7.8 不支持 **Calico Vxlan IPv6**。

**CentOS**

- **支持版本及内核：**
  - CentOS 7.6 至 7.9：`3.10.0-1127` 至 `3.11`
- **注意：** 不支持 **Calico Vxlan IPv6**。

**Ubuntu**

- **支持版本及内核：**
  - Ubuntu 20.04 LTS：`5.4.0-124-generic`
  - Ubuntu 22.04 LTS：`5.15.0-56-generic`
- **注意：** 不支持 Ubuntu HWE（Hardware Enablement）版本。

**银河麒麟 (Kylin Linux Advanced Server)**

- **支持版本及内核：**
  - 麒麟 V10：`4.19.90-11.ky10.x86_64`
  - 麒麟 V10 SP1：`4.19.90-23.8.v2101.ky10.x86_64`
  - 麒麟 V10 SP2：`4.19.90-24.4.v2101.ky10.x86_64`
  - 麒麟 V10 SP3：`4.19.90-52.22.v2207.ky10.x86_64`
- **重要提示：** 麒麟 V10、V10-SP1、V10-SP2 存在已知内核问题，可能导致 **NodePort 网络访问失败**；建议升级至 **麒麟 V10-SP3**。

---

#### 2.2 ARM 架构（鲲鹏 920）

**银河麒麟 (Kylin Linux Advanced Server)**

- **支持版本及内核：**
  - 麒麟 V10：`4.19.90-11.ky10.aarch64`
  - 麒麟 V10 SP1：`4.19.90-17.ky10.aarch64`
  - 麒麟 V10 SP2：`4.19.90-24.4.v2101.ky10.aarch64`
  - 麒麟 V10 SP3：`4.19.90-52.22.v2207.ky10.aarch64`
- **重要提示：** 同样建议升级至 **麒麟 V10-SP3** 以避免 NodePort 网络访问问题。

---

#### 2.3 其他注意事项

1. **内核版本要求：**
   以上内核版本为官方发布且经过平台测试验证。实际部署时，确保 **A.B.C 主版本号** 一致即可，后续部分允许存在差异。

2. **不支持的环境：**
   若操作系统、内核版本或 CPU 架构不符合要求，请联系技术支持。

3. **自定义系统部署：**
   使用定制系统或特殊环境部署前，请完成兼容性测试，并根据实际情况调整。

4. **Ceph 部署要求：**
   若计划安装 Ceph，请确保内核版本不低于 `4.11`。

---

### 3. 机器预处理

在安装管理集群前，所有节点（控制节点及计算节点）必须完成预处理工作。

#### 3.1 执行快速配置脚本

**准备**
确认安装包已解压，并确保具备 `root` 权限。

**执行**
运行位于 `res/init.sh` 的脚本：

```bash
bash res/init.sh
```

**验证**
检查脚本日志，确认系统配置项已按要求设置。

**注意：** `init.sh` 不能保证以下的所有检查项都得到妥善处理，您仍然需要继续下述步骤确认每台机器都满足了检查项的全部要求。

#### 3.2 核对本机检查项

逐项检查以下要求，确保本机环境满足安装需求：

- **操作系统与内核配置：**

  - [x] grub 启动配置包含 `transparent_hugepage=never` 参数。
  - [!] CentOS 7.x 系统须在 grub 配置中添加 `cgroup.memory=nokmem` 参数。
  - [x] 内核版本低于 4.19.0（或 RHEL 低于 4.18.0）时，确保 `nf_conntrack_ipv4` 与（IPv6 时）`nf_conntrack_ipv6` 模块启用。
  - [!] 若使用 `Kube-OVN` CNI，必须启用 `geneve` 与 `openvswitch` 模块。
  - [x] 检查 `ip_vs`、`ip_vs_rr`、`ip_vs_wrr`、`ip_vs_sh` 模块加载状态。
  - [x] 关闭 apparmor/selinux 及防火墙功能。
  - [x] 禁用 swap。

- **用户与权限设置：**

  - [x] SSH 用户具备 `root` 权限，并可无密码使用 `sudo`。
  - [x] `/etc/ssh/sshd_config` 中 `UseDNS` 与 `UsePAM` 参数设置为 `no`。
  - [x] `systemctl show --property=DefaultTasksMax` 返回 `infinity` 或极大数值；否则调整 `/etc/systemd/system.conf`。

- **网络与主机名：**

  - [x] 主机名要求：不超过36字符，以字母或数字开头和结尾，仅含小写字母、数字、`-` 与 `.`（不得含 `.-`、`..` 或 `-.`）。
  - [x] `/etc/hosts` 中 `localhost` 应解析为 `127.0.0.1`。
  - [x] `/etc/resolv.conf` 文件存在且含 `nameserver` 配置，但不得含 172 开头地址（禁用 systemd-resolved）。
  - [!] `/etc/resolv.conf` 中不应配置 search 域（如需配置，请参见 [配置 Search 域](#config_search)）。
  - [x] IP 地址不得为回环、组播、链路本地、全0或广播地址。
  - [x] `ip route` 输出须包含默认路由或指向 `0.0.0.0` 的路由。
  - [x] 管理集群各节点不得占用以下端口：
    - **控制节点：** 2379、2380、6443、10249-10256
    - **安装器节点：** 8080、12080、12443、16443 及所有控制节点端口
    - **计算节点：** 10249-10256
  - [x] 若使用 **Kube-OVN** 或 **Calico**，确保以下端口未占用：
    - **Kube-OVN：** 6641、6642
    - **Calico：** 179
  - [!] 确保 Docker 所需的 172.16.x.x 至 172.32.x.x 网段未占用，如有冲突请联系技术支持。

- **软件与目录要求：**
  - [x] 确保系统中安装 `ip`、`ss`、`tar`、`swapoff`、`modprobe`、`sysctl`、`md5sum` 及 `scp` 或 `sftp` 命令。
  - [!] 若使用本地存储方案（如 TopoLVM 或 Rook），请安装 `lvm2`。
  - [x] 不允许存在 `/etc/systemd/system/kubelet.service` 文件。
  - [x] 清理以下目录中的文件：
    - `/var/lib/docker`
    - `/var/lib/containerd`
    - `/var/log/pods`
    - `/var/lib/kubelet/pki`
  - [x] 检查 `/var/lib` 可用空间是否充足。
  - [x] `/tmp` 挂载参数中不得含 `noexec`。
  - [x] 移除可能与平台组件冲突的软件包（详见 [移除冲突软件包](#remove_conflicting_packages)）。

#### 3.3 跨节点检查项

- 各节点之间必须无网络防火墙限制。
- 各节点的 hostname 必须唯一。
- 所有节点时区统一，时间同步误差不得超过 10 秒。

---

### 4. 附录

#### 4.1 移除冲突软件包 <a id="remove_conflicting_packages"></a>

请根据所在操作系统，使用下列命令检查并卸载可能与平台组件冲突的软件包。

**_CentOS / RedHat_**

**检查命令：**

```bash
for x in \
    docker docker-client docker-common docker-latest \
    podman-docker podman \
    runc \
    containernetworking-plugins \
    apptainer \
    kubernetes kubernetes-master kubernetes-node kubernetes-client; do
    rpm -qa | grep -F "$x"
done
```

**卸载命令：**

```bash
for x in \
    docker docker-client docker-common docker-latest \
    podman-docker podman \
    runc \
    containernetworking-plugins \
    apptainer \
    kubernetes kubernetes-master kubernetes-node kubernetes-client; do
    yum remove "$x"
done
```

**_Ubuntu_**

**检查命令：**

```bash
for x in \
    docker.io \
    podman-docker \
    containerd \
    rootlesskit \
    rkt \
    containernetworking-plugins \
    kubernetes; do
    dpkg-query -l | grep -F "$x"
done

for x in \
    kubernetes-worker \
    kubectl kube-proxy kube-scheduler kube-controller-manager kube-apiserver \
    k8s microk8s \
    kubeadm kubelet; do
    snap list | grep -F "$x"
done
```

**卸载命令：**

```bash
for x in \
    docker.io \
    podman-docker \
    containerd \
    rootlesskit \
    rkt \
    containernetworking-plugins \
    kubernetes; do
    apt-get purge "$x"
done

for x in \
    kubernetes-worker \
    kubectl kube-proxy kube-scheduler kube-controller-manager kube-apiserver \
    k8s microk8s \
    kubeadm kubelet; do
    snap remove --purge "$x"
done
```

**_KylinOS_**

**检查命令：**

```bash
for x in \
    docker docker-client docker-common \
    docker-engine docker-proxy docker-runc \
    podman-docker podman \
    containernetworking-plugins \
    apptainer \
    containerd \
    kubernetes kubernetes-master kubernetes-node kubernetes-client kubernetes-kubeadm; do
    rpm -qa | grep -F "$x"
done
```

**卸载命令：**

```bash
for x in \
    docker docker-client docker-common \
    docker-engine docker-proxy docker-runc \
    podman-docker podman \
    containernetworking-plugins \
    apptainer \
    containerd \
    kubernetes kubernetes-master kubernetes-node kubernetes-client kubernetes-kubeadm; do
    yum remove "$x"
done
```

---

#### 4.2 配置 Search 域 <a id="config_search"></a>

在 `/etc/resolv.conf` 文件中，`search` 行指定 DNS 查询搜索路径，其配置要求如下：

- **域名数量**：主机的 search 域数量应小于 `domainCountLimit - 3`（默认 `domainCountLimit` 为 32）。
- **总字符长度**：所有域名及空格总字符数不得超过 `MaxDNSSearchListChar`（通常为 2048）。
- **单个域名长度**：每个域名不得超过 253 个字符。

如不符合要求，可能导致 DNS 查询失败或性能下降，请联系运维工程师调整。

---

### 5. 网络资源要求

在安装管理集群前，以下网络资源必须提前配置。若无法提供硬件 LoadBalancer，安装器支持配置 **haproxy + keepalived** 作为软负载均衡，但可能影响性能与可靠性。

#### 5.1 网络资源配置

| **资源**        | **是否必须** | **数量** | **说明**                                                                                                                            |
| --------------- | ------------ | -------- | ----------------------------------------------------------------------------------------------------------------------------------- |
| **global VIP**  | 必须         | 1        | 用于管理集群各节点访问 kube-apiserver，配置于负载均衡设备中以确保高可用性。若管理集群与业务集群处于同一网络，此 IP 为唯一访问入口。 |
| **External IP** | 可选         | 1        | 用于跨网络（如混合云）访问管理集群，配置于负载均衡设备中；亦可作为平台 Web UI 的访问地址。                                          |
| **域名**        | 可选         | 1        | 若需通过域名访问管理集群或平台 Web UI，请提前提供，并确保域名解析正确。                                                             |
| **证书**        | 可选         | 1        | 推荐使用受信任证书以避免浏览器安全警告；如未提供，安装器会生成自签名证书，但使用 HTTPS 时可能提示安全风险。                         |

**特别说明**
以下情况必须提供域名：

1. 支持管理集群 IPv6 访问；
2. 实施管理集群容灾方案。

#### 5.2 网络配置要求

| **类型**        | **要求说明**                                                                                                                                              |
| --------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **网络速率**    | 同一网络内管理集群与业务集群速率 ≥1Gbps（建议10Gbps）；跨网络速率 ≥100Mbps（建议1Gbps）。不足速率将影响日志及审计查询性能。                               |
| **网络时延**    | 同一网络时延 ≤2ms；跨网络时延 ≤100ms（建议 ≤30ms）。                                                                                                      |
| **网络策略**    | 建议管理集群与业务集群之间无防火墙限制；如有限制，请参照 [端口转发规则](#port-forward) 确保必要端口开放；使用 Calico CNI 时，确保启用 **IP-in-IP** 协议。 |
| **IP 地址范围** | 管理集群节点应避免使用 172.16-32 网段，如已使用，请调整 Docker 配置（添加 bip 参数）以避免冲突。                                                          |

#### 5.3 端口转发规则 <a id="port-forward"></a>

为确保管理集群能够正常接收 LoadBalancer 转发的外部流量，请配置以下规则：

| **访问源/源IP**  | **转发协议** | **目的IP**        | **目的端口** | **备注**                                                                              |
| ---------------- | ------------ | ----------------- | ------------ | ------------------------------------------------------------------------------------- |
| 用户 PC 或 `any` | TCP          | 安装器执行节点 IP | 8080         | 浏览器访问安装管理集群 Web UI，安装完成后可删除此规则。                               |
| LoadBalancer     | TCP          | 控制节点 IP       | 443          | 默认 HTTPS 端口，用于平台 Web UI、镜像仓库及 apiserver 外部访问，支持安装参数自定义。 |

**其他配置要求：**

1. **LoadBalancer 设置：**

   - 具体配置方法请参见相关文档。
   - 建议配置健康检查以监控端口状态。

2. **容灾方案：**

   - 若计划容灾，需为所有控制节点开放端口 2379，用于主集群与灾备集群间 ETCD 数据同步。

3. **HTTP 支持：**
   - 平台默认仅支持 HTTPS；如需 HTTP 支持，请额外配置端口 80（或自定义端口），其余规则与 HTTPS 配置一致。
